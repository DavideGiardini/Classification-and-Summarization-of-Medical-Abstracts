{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170c0c0d-eaec-4d20-be67-c452ac1695a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_30436\\2073477184.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from TMfunctions import *\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817af37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc67918",
   "metadata": {},
   "source": [
    "# No PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc5e19",
   "metadata": {},
   "source": [
    "## Feature Extraction: BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159a8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/No PreProcessing/train.csv', index_col=0)\n",
    "test = pd.read_csv('Data/No PreProcessing/test.csv', index_col=0)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b0dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [25:51<00:00, 310.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.647, 'RF': 0.638, 'NB': 0.526}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [36:38<00:00, 439.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n",
      "{'DT': 0.658, 'RF': 0.651, 'NB': 0.527}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [41:45<00:00, 501.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n",
      "{'DT': 0.659, 'RF': 0.647, 'NB': 0.523}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [42:04<00:00, 504.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4:\n",
      "{'DT': 0.653, 'RF': 0.638, 'NB': 0.532}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [39:41<00:00, 476.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5:\n",
      "{'DT': 0.648, 'RF': 0.658, 'NB': 0.535}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.653, 'RF': 0.6464000000000001, 'NB': 0.5286000000000001}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    cv_matrix = cv.fit_transform(train['medical_abstract'])\n",
    "    FE_train = cv_matrix.toarray()\n",
    "    cv_matrix =  cv.transform(test['medical_abstract'])\n",
    "    FE_test = cv_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9aec96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0.653, 'RF': 0.6464000000000001, 'NB': 0.5286000000000001}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744c547",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb773f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/No PreProcessing/train.csv', index_col=0)\n",
    "test = pd.read_csv('Data/No PreProcessing/test.csv', index_col=0)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4ec90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [42:18<00:00, 507.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.655, 'RF': 0.626, 'NB': 0.534}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [43:05<00:00, 517.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n",
      "{'DT': 0.659, 'RF': 0.654, 'NB': 0.53}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [42:38<00:00, 511.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n",
      "{'DT': 0.653, 'RF': 0.644, 'NB': 0.533}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [43:26<00:00, 521.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4:\n",
      "{'DT': 0.65, 'RF': 0.64, 'NB': 0.54}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [40:29<00:00, 485.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5:\n",
      "{'DT': 0.645, 'RF': 0.644, 'NB': 0.536}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6524, 'RF': 0.6416000000000001, 'NB': 0.5346}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    cv_matrix = cv.fit_transform(train['medical_abstract'])\n",
    "    FE_train = cv_matrix.toarray()\n",
    "    cv_matrix =  cv.transform(test['medical_abstract'])\n",
    "    FE_test = cv_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1cc04f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0.6524, 'RF': 0.6416000000000001, 'NB': 0.5346}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3257e73",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382f726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/No PreProcessing/train.csv', index_col=0)\n",
    "test = pd.read_csv('Data/No PreProcessing/test.csv', index_col=0)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [41:42<00:00, 500.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.64, 'RF': 0.636, 'NB': 0.521}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [41:47<00:00, 501.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n",
      "{'DT': 0.644, 'RF': 0.664, 'NB': 0.52}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    tfidf_matrix = tfidf.fit_transform(train['medical_abstract'])\n",
    "    FE_train = tfidf_matrix.toarray()\n",
    "    tfidf_matrix =  tfidf.transform(test['medical_abstract'])\n",
    "    FE_test = tfidf_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99808f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [37:17<00:00, 447.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n",
      "{'DT': 0.648, 'RF': 0.646, 'NB': 0.517}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [45:13<00:00, 542.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4:\n",
      "{'DT': 0.635, 'RF': 0.632, 'NB': 0.53}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [47:20<00:00, 568.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5:\n",
      "{'DT': 0.641, 'RF': 0.656, 'NB': 0.524}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6416000000000001, 'RF': 0.6468, 'NB': 0.5224}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "Kresults = [{'DT': 0.64, 'RF': 0.636, 'NB': 0.521}, {'DT': 0.644, 'RF': 0.664, 'NB': 0.52}]\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    if fold in [1,2]:\n",
    "        continue\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    tfidf_matrix = tfidf.fit_transform(train['medical_abstract'])\n",
    "    FE_train = tfidf_matrix.toarray()\n",
    "    tfidf_matrix =  tfidf.transform(test['medical_abstract'])\n",
    "    FE_test = tfidf_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5fdb76",
   "metadata": {},
   "source": [
    "# PreProcessing: StopWords removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddffb2-23e0-47a0-8080-b412891d45a6",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07948f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/StopWords/train.csv', index_col=0)\n",
    "test = pd.read_csv('Data/StopWords/test.csv', index_col=0)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fde5e3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 1:\n",
      "{'DT': 0.65, 'RF': 0.661, 'NB': 0.532}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 2:\n",
      "{'DT': 0.646, 'RF': 0.674, 'NB': 0.54}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 3:\n",
      "{'DT': 0.654, 'RF': 0.663, 'NB': 0.56}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 4:\n",
      "{'DT': 0.657, 'RF': 0.684, 'NB': 0.528}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 5:\n",
      "{'DT': 0.654, 'RF': 0.658, 'NB': 0.531}\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6522, 'RF': 0.6679999999999999, 'NB': 0.5382}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    cv_matrix = cv.fit_transform(train['medical_abstract'])\n",
    "    FE_train = cv_matrix.toarray()\n",
    "    cv_matrix =  cv.transform(test['medical_abstract'])\n",
    "    FE_test = cv_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1847cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0.6522, 'RF': 0.6679999999999999, 'NB': 0.5382}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41ccfa-bde4-4855-890b-d6d07bbd3814",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e6cb51-ca81-4be3-8469-284db3f1f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/StopWords/train.csv', index_col=0)\n",
    "test = pd.read_csv('Data/StopWords/test.csv', index_col=0)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e40ad2-faa5-4796-ae86-f1f35c4b99e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 1:\n",
      "{'DT': 0.656, 'RF': 0.678, 'NB': 0.543}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 2:\n",
      "{'DT': 0.656, 'RF': 0.677, 'NB': 0.542}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 3:\n",
      "{'DT': 0.663, 'RF': 0.674, 'NB': 0.555}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 4:\n",
      "{'DT': 0.651, 'RF': 0.695, 'NB': 0.54}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 5:\n",
      "{'DT': 0.66, 'RF': 0.669, 'NB': 0.534}\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6572000000000001, 'RF': 0.6786, 'NB': 0.5428000000000001}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    cv_matrix = cv.fit_transform(train['medical_abstract'])\n",
    "    FE_train = cv_matrix.toarray()\n",
    "    cv_matrix =  cv.transform(test['medical_abstract'])\n",
    "    FE_test = cv_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec3252-5a6c-4669-8858-426800734351",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27945a75-3ba5-4460-b8a6-cd9750326f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/StopWords/train.csv', index_col=0)\n",
    "test = pd.read_csv('Data/StopWords/test.csv', index_col=0)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f81a39c-98e3-4d69-a1c5-4ca189235f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 1:\n",
      "{'DT': 0.641, 'RF': 0.67, 'NB': 0.528}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 2:\n",
      "{'DT': 0.654, 'RF': 0.676, 'NB': 0.533}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 3:\n",
      "{'DT': 0.652, 'RF': 0.683, 'NB': 0.544}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 4:\n",
      "{'DT': 0.647, 'RF': 0.688, 'NB': 0.527}\n",
      " \n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "DT done\n",
      "RF done\n",
      "NB done\n",
      "fold 5:\n",
      "{'DT': 0.649, 'RF': 0.673, 'NB': 0.524}\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6486000000000001, 'RF': 0.6779999999999999, 'NB': 0.5312}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    tfidf_matrix = tfidf.fit_transform(train['medical_abstract'])\n",
    "    FE_train = tfidf_matrix.toarray()\n",
    "    tfidf_matrix =  tfidf.transform(test['medical_abstract'])\n",
    "    FE_test = tfidf_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a49fc96-6c9b-4972-b40a-64aa4a864352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0.6486000000000001, 'RF': 0.6779999999999999, 'NB': 0.5312}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3a2db",
   "metadata": {},
   "source": [
    "# PreProcessing: StopWords removal + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d5dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/StopWords + Lemm/train.csv', index_col=1)\n",
    "test = pd.read_csv('Data/StopWords + Lemm/test.csv', index_col=1)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6492ba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [36:25<00:00, 437.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.652, 'RF': 0.654, 'NB': 0.532}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [31:14<00:00, 374.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n",
      "{'DT': 0.642, 'RF': 0.664, 'NB': 0.537}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [35:40<00:00, 428.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n",
      "{'DT': 0.661, 'RF': 0.663, 'NB': 0.562}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [35:44<00:00, 428.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4:\n",
      "{'DT': 0.653, 'RF': 0.671, 'NB': 0.53}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [32:45<00:00, 393.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5:\n",
      "{'DT': 0.651, 'RF': 0.654, 'NB': 0.535}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6518, 'RF': 0.6612, 'NB': 0.5392}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    cv_matrix = cv.fit_transform(train['medical_abstract'])\n",
    "    FE_train = cv_matrix.toarray()\n",
    "    cv_matrix =  cv.transform(test['medical_abstract'])\n",
    "    FE_test = cv_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450159b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0.6518, 'RF': 0.6612, 'NB': 0.5392}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fdf8b1",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77685b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/StopWords + Lemm/train.csv', index_col=1)\n",
    "test = pd.read_csv('Data/StopWords + Lemm/test.csv', index_col=1)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81eff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [38:27<00:00, 461.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.652, 'RF': 0.668, 'NB': 0.541}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [34:32<00:00, 414.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n",
      "{'DT': 0.659, 'RF': 0.682, 'NB': 0.537}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [34:51<00:00, 418.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n",
      "{'DT': 0.665, 'RF': 0.683, 'NB': 0.554}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [38:49<00:00, 465.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4:\n",
      "{'DT': 0.656, 'RF': 0.691, 'NB': 0.538}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [35:02<00:00, 420.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5:\n",
      "{'DT': 0.662, 'RF': 0.666, 'NB': 0.536}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6588, 'RF': 0.678, 'NB': 0.5412}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    cv_matrix = cv.fit_transform(train['medical_abstract'])\n",
    "    FE_train = cv_matrix.toarray()\n",
    "    cv_matrix =  cv.transform(test['medical_abstract'])\n",
    "    FE_test = cv_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f75898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0.6588, 'RF': 0.678, 'NB': 0.5412}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ec694",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6339ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train = pd.read_csv('Data/StopWords + Lemm/train.csv', index_col=1)\n",
    "test = pd.read_csv('Data/StopWords + Lemm/test.csv', index_col=1)\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da06df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [35:48<00:00, 429.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.645, 'RF': 0.664, 'NB': 0.529}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [35:30<00:00, 426.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n",
      "{'DT': 0.646, 'RF': 0.676, 'NB': 0.529}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [24:41<17:26, 523.44s/it]"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    tfidf_matrix = tfidf.fit_transform(train['medical_abstract'])\n",
    "    FE_train = tfidf_matrix.toarray()\n",
    "    tfidf_matrix =  tfidf.transform(test['medical_abstract'])\n",
    "    FE_test = tfidf_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105c896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [30:26<00:00, 365.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n",
      "{'DT': 0.645, 'RF': 0.69, 'NB': 0.542}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [32:25<00:00, 389.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4:\n",
      "{'DT': 0.647, 'RF': 0.683, 'NB': 0.528}\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [45:28<00:00, 545.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5:\n",
      "{'DT': 0.65, 'RF': 0.673, 'NB': 0.526}\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.6466000000000001, 'RF': 0.6772, 'NB': 0.5307999999999999}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "Kresults = [{'DT': 0.645, 'RF': 0.664, 'NB': 0.529}, {'DT': 0.646, 'RF': 0.676, 'NB': 0.529}]\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    if fold in [1,2]:\n",
    "        continue\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    tfidf_matrix = tfidf.fit_transform(train['medical_abstract'])\n",
    "    FE_train = tfidf_matrix.toarray()\n",
    "    tfidf_matrix =  tfidf.transform(test['medical_abstract'])\n",
    "    FE_test = tfidf_matrix.toarray()\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "104250a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DT': 0.6466000000000001, 'RF': 0.6772, 'NB': 0.5307999999999999}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMiningK",
   "language": "python",
   "name": "textminingk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
