{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53186427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20212\\803022442.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from TMfunctions import *\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b226f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dde96",
   "metadata": {},
   "source": [
    "# Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c527368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model can be downloaded from https://bio.nlplab.org/\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('Pretrained Models/PubMed-and-PMC-w2v.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb7999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/StopWords/train.csv', index_col = 0)\n",
    "test = pd.read_csv('Data/StopWords/test.csv', index_col = 0)\n",
    "data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ec7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [model[word] for word in words if word in model]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb680f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.537, 'RF': 0.612, 'NB': 0.653}\n",
      " \n",
      "fold 2:\n",
      "{'DT': 0.546, 'RF': 0.608, 'NB': 0.658}\n",
      " \n",
      "fold 3:\n",
      "{'DT': 0.544, 'RF': 0.629, 'NB': 0.669}\n",
      " \n",
      "fold 4:\n",
      "{'DT': 0.542, 'RF': 0.622, 'NB': 0.668}\n",
      " \n",
      "fold 5:\n",
      "{'DT': 0.538, 'RF': 0.61, 'NB': 0.662}\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.5414000000000001, 'RF': 0.6162, 'NB': 0.662}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    FE_train = pd.DataFrame(np.array([vectorize(doc) for doc in train['medical_abstract']]))\n",
    "    FE_test = pd.DataFrame(np.array([vectorize(doc) for doc in test['medical_abstract']]))\n",
    "    \n",
    "    Kresult = micro_f1(build_results(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB = 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23a15be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'DT': 0.535, 'RF': 0.612, 'NB': 0.653, 'SVM': 0.707}\n",
      " \n",
      "fold 2:\n",
      "{'DT': 0.545, 'RF': 0.62, 'NB': 0.658, 'SVM': 0.715}\n",
      " \n",
      "fold 3:\n",
      "{'DT': 0.55, 'RF': 0.632, 'NB': 0.669, 'SVM': 0.722}\n",
      " \n",
      "fold 4:\n",
      "{'DT': 0.547, 'RF': 0.621, 'NB': 0.668, 'SVM': 0.709}\n",
      " \n",
      "fold 5:\n",
      "{'DT': 0.54, 'RF': 0.598, 'NB': 0.662, 'SVM': 0.704}\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DT': 0.5434, 'RF': 0.6165999999999999, 'NB': 0.662, 'SVM': 0.7114}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "fold = 0\n",
    "Kresults = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold += 1\n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    \n",
    "    FE_train = pd.DataFrame(np.array([vectorize(doc) for doc in train['medical_abstract']]))\n",
    "    FE_test = pd.DataFrame(np.array([vectorize(doc) for doc in test['medical_abstract']]))\n",
    "    \n",
    "    Kresult = micro_f1SVM(build_resultsSVM(FE_train, FE_test, train, test))\n",
    "    Kresults.append(Kresult)\n",
    "    print(\"fold \" + str(fold) + \":\")\n",
    "    print(Kresult)\n",
    "    print(\" \")\n",
    "    \n",
    "    DT, RF, NB, SVM = 0, 0, 0, 0\n",
    "    for result in Kresults:\n",
    "        DT += result['DT']\n",
    "        RF += result['RF']\n",
    "        NB += result['NB']\n",
    "        SVM += result['SVM']\n",
    "    result = {'DT': DT/5, 'RF': RF/5, 'NB': NB/5, 'SVM': SVM/5}\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMiningK",
   "language": "python",
   "name": "textminingk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
